{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<img src=\"https://assets.newatlas.com/dims4/default/3461759/2147483647/strip/true/crop/7360x4907+0+3/resize/840x560!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F10%2F7f%2F5e48f79245c0b831a58d7cf8fb1d%2Fdepositphotos-228244172-xl.jpg\" width=\"900\" align=\"center\">","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"background-color:#6b5b95; font-family:newtimeroman;color:#FFF9ED;font-size:220%; text-align:center; border-radius: 15px 55px;\">Diabetes | EDA & Prediction üìù An ML Guide for Beginners</p>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px;\n            border : black solid;\n            background-color: #5b9aa0;\n            font-size:100%;\n            text-align: left\">\n    \n<h2 style='; border:0; border-radius: 15px; font-weight: bold; font-size:220%; color:white'><center> ‚úç‚úç Purpose of the Project ‚úç‚úç</center></h2>  \n\n<b> Excelling at any discipline may be a tiring stage for those having difficulties to work on the same subject for a long time. Because learning new things is not a linear process in most cases. Even with shedding blood and sweat, it takes a lot of time to make a significant progress. However, beginners tend to disregard the truth in hope of finding a short way to achieve their goal. This goes for the data science enthusiasts as well. </b>\n\n<b> Unfortunately, such a way doesn't exist. Unlike this misleading mindset, we should complete the necessary stages to make a progress in anything we want. </b>\n\n<b> As for  how we can improve our skills in Data Science and Machine Learning, developing portfolio projects is the best method as you guess. Hence, we aim to create a prediction project in this guide by explaining the basic steps to make it comprehensible for beginners. </b>","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"background-color:#6b5b95; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ú® Business Problem ‚ú®</p>","metadata":{}},{"cell_type":"markdown","source":"<strong> Before diving into technical aspects of ML projects, the first step is always defining the business (or scientific) problem related to data. </strong>\n\nHere, we have a dataset published by National Institute of Diabetes and Digestive and Kidney Diseases in the USA, which contains information about patients with or without diabetes. \n\nOur purpose is to predict if a patient has diabetes or not, using the measurements in the dataset. To be able to predict it correctly, we need to grasp the <b>domain knowledge </b>, which will be provided in the next stage. \n\n### Additional Note: \n\n<blockquote> In data science, the term domain knowledge is used to refer to the general background knowledge of the field or environment to which the methods of data science are being applied. </blockquote>\n\nEven though it is a vital part of data science alongside computer science and machine learning/statistics, it is usually overlooked by novices due to unawareness. \n\nImagine a data scientist employed in the banking, defense, telecom or any other industry without knowing the bare bones of that field. How far do you think they can get ahead in that position under these circumstances. Not much, I guess. \n\nAs for how we can obtain domain knowledge, we should choose a field we are interested in (for example sport analytics, neuroscience, autonome systems etc.), then learn the basics of it gradually and develop projects eventually.\n\n<b> For further reading: </b> <br>\nhttps://www.indeed.com/career-advice/career-development/what-is-domain-knowledge#:~:text=Domain%20knowledge%20is%20the%20understanding,or%20specializations%20in%20an%20industry.","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"background-color:#6b5b95; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚öõ Dataset Explanation ‚öõ</p>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px;\n            border : black solid;\n            background-color: #5b9aa0;\n            font-size:100%;\n            text-align: left\">\n    \n<h2 style='; border:0; border-radius: 15px; font-weight: bold; font-size:220%; color:white'><center> Explanation of the Variables </center></h2> \n    \n* ****Pregnancies:**** Number of times pregnant\n* ****Glucose:**** Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n* ****Blood Pressure:**** Diastolic blood pressure (mm Hg)\n* ****SkinThickness:**** Triceps skin fold thickness (mm)\n* ****Insulin:**** 2-Hour serum insulin (mu U/ml)\n* ****DiabetsPedigreeFunction:**** A function that calculates the probability of having diabetes according to one's descendants\n* ****BMI:**** Body mass index (weight in kg/(height in m)^2)\n* ****Age:**** Age (years)\n* ****Outcome:**** Class variable (0 or 1)","metadata":{}},{"cell_type":"markdown","source":"In addition to the information given above, we should also know the BMI scale. The image below shows its classes that will be useful to us in data preprocessing.","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://www.cdc.gov/healthyweight/images/assessing/bmi-adult-fb-600x315.jpg?_=07167\" width=\"900\" align=\"center\">","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"background-color:#6b5b95; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ôª Project Life Cycle ‚ôª </p>","metadata":{}},{"cell_type":"markdown","source":"Every software project is designed in accordance with the <b> SDLC (Sofware Development Life Cycle) </b> principles to some degree. Even though a detailed review of SDLC is out of the scope in this project, we are going to touch on the subject nevertheless.\n\nDesigning a process for machine learning project depends on the situation. A general approach for industry standards is given below.\n\n<img src=\"https://nearlearn.com/blog/wp-content/uploads/2020/11/How-can-I-start-a-career-in-artificial-intelligence_-10-1024x683.png\" width=\"800\" align=\"center\">\n\n","metadata":{}},{"cell_type":"markdown","source":"As for the narrowed down projects that contain static components, the steps after Test Model can be excluded. Many portfolio projects in Kaggle can be given as an example for this approach and our project will be designed accordingly. ","metadata":{}},{"cell_type":"markdown","source":"# Notebook Content","metadata":{}},{"cell_type":"markdown","source":"<div class=\"inner_cell\">\n<div class=\"text_cell_render border-box-sizing rendered_html\">\n<p></p><div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n  <h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" role=\"tab\" aria-controls=\"home\" style = \"border:2px solid #581845;background-color:#6b5b95; color:white; font-family:Verdana; font-size:140%;font-weight: Bold;\">Notebook Content</h3>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#1\" role=\"tab\" aria-controls=\"profile\" target=\"_self\" style = \"color:#034f84; font-family:Verdana; font-size:120%;font-weight: Bold;\">Import Libraries<span class=\"badge badge-primary badge-pill\">1</span></a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#2\" role=\"tab\" aria-controls=\"profile\" target=\"_self\" style = \"color:#034f84; font-family:Verdana; font-size:120%;font-weight: Bold;\">Load and Check Data<span class=\"badge badge-primary badge-pill\">2</span></a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#3\" role=\"tab\" aria-controls=\"profile\" target=\"_self\" style = \"color:#034f84; font-family:Verdana; font-size:120%;font-weight: Bold;\">Exploratory Data Analysis<span class=\"badge badge-primary badge-pill\">3</span></a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#4\" role=\"tab\" aria-controls=\"profile\" target=\"_self\" style = \"color:#034f84; font-family:Verdana; font-size:120%;font-weight: Bold;\">Data Preprocessing<span class=\"badge badge-primary badge-pill\">4</span></a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#5\" role=\"tab\" aria-controls=\"profile\" target=\"_self\" style = \"color:#034f84; font-family:Verdana; font-size:120%;font-weight: Bold;\">Models<span class=\"badge badge-primary badge-pill\">5</span></a>\n    \n</div>\n</div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<a id = \"1\"></a>\n# <p style=\"background-color:#6b5b95; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚òÄ Import Libraries ‚òÄ</p>","metadata":{}},{"cell_type":"code","source":"# Classic Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#Advanced Visualization Libraries\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected = True) #enables plotly plots to be displayed in notebook\ncmap1 = \"gist_gray\"\n\n#Models\nfrom lightgbm import LGBMClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\n\n#Metrics, Preprocessing and Tuning Tools\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import plot_roc_curve\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.impute import KNNImputer\nfrom sklearn.preprocessing import MinMaxScaler\nimport missingno as msno\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\n\n#Customization\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom termcolor import colored","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:29:58.797048Z","iopub.execute_input":"2023-04-27T08:29:58.79784Z","iopub.status.idle":"2023-04-27T08:30:06.421112Z","shell.execute_reply.started":"2023-04-27T08:29:58.797785Z","shell.execute_reply":"2023-04-27T08:30:06.419326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have imported the necessary libraries. As you can realize, they were categorized according to their utilizatons. Let's explain that. \n\nIn the early stages of machine learning projects in Python, developers would generally used Numpy, Pandas, Matplotlib and then Seaborn. As a result, they became the backbone of the many core elements in terms of mathematical operations, data manipulations and visualizations. Later on, many more libraries have been developed and begun to be used by the community. \n\nThese classic libraries are still the most important components of ML projects and competitive alternatives to Numpy and Pandas have yet to exist. However, despite their functionalities, Matplotlib and Seaborn lack interactivity and some aesthetical features. That's why, Plotly have become one of the most popular visualization tools in data science in the recent years. There are also many useful alternatives like Altair, Gleam, GGPlot etc.\n\nOn the other hand, we generally use Sklearn to model data. It includes classic machine learning algorithms like Logistic Regression, Decision Trees, KNN etc and tools for metrics, data preprocessing and tuning. Additionally, we have many modern algorithms coming from separate libraries like CatBoost, LGBM, XGBoost etc. \n\nFor customized purposes like printing colorful strings and excluding warning messages due to depreciated functions, we are going to use Warnings and Termcolor.","metadata":{}},{"cell_type":"markdown","source":"<a id = \"2\"></a>\n# <p style=\"background-color:#6b5b95; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚á£ Load and Check Data ‚á£</p>","metadata":{}},{"cell_type":"code","source":"diabetes = pd.read_csv(\"/kaggle/input/pima-indians-diabetes-database/diabetes.csv\")\ndf = diabetes.copy()","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:06.4242Z","iopub.execute_input":"2023-04-27T08:30:06.424612Z","iopub.status.idle":"2023-04-27T08:30:06.453178Z","shell.execute_reply.started":"2023-04-27T08:30:06.424572Z","shell.execute_reply":"2023-04-27T08:30:06.451808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:06.455577Z","iopub.execute_input":"2023-04-27T08:30:06.456134Z","iopub.status.idle":"2023-04-27T08:30:06.490411Z","shell.execute_reply.started":"2023-04-27T08:30:06.456086Z","shell.execute_reply":"2023-04-27T08:30:06.488983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After loading data, we should copy it and create a separate variable. If we run into a problem because of preprocessing steps or wrong codes etc, this operation will enable us to read original data from the backup dataset.","metadata":{}},{"cell_type":"code","source":"def check_data(df):\n    print(80 * \"*\")\n    print('DIMENSION: ({}, {})'.format(df.shape[0], df.shape[1]))\n    print(80 * \"*\")\n    print(\"COLUMNS:\\n\")\n    print(df.columns.values)\n    print(80 * \"*\")\n    print(\"DATA INFO:\\n\")\n    print(df.dtypes)\n    print(80 * \"*\")\n    print(\"MISSING VALUES:\\n\")\n    print(df.isnull().sum())\n    print(80 * \"*\")\n    print(\"NUMBER OF UNIQUE VALUES:\\n\")\n    print(df.nunique())\n    \ncheck_data(df)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:06.4942Z","iopub.execute_input":"2023-04-27T08:30:06.495082Z","iopub.status.idle":"2023-04-27T08:30:06.519437Z","shell.execute_reply.started":"2023-04-27T08:30:06.495024Z","shell.execute_reply":"2023-04-27T08:30:06.517163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def grab_col_names(dataframe, cat_th=10, car_th=20):\n    \n    # cat_cols, cat_but_car\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\"]\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n    cat_cols = cat_cols + num_but_cat\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    # num_cols\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n\n    print(\" RESULT \".center(50, \"-\"))\n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n    print(\"\".center(50, \"-\"))\n    \n    return cat_cols, num_cols, cat_but_car\n\ncat_cols, num_cols, cat_but_car = grab_col_names(df)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:06.522897Z","iopub.execute_input":"2023-04-27T08:30:06.523354Z","iopub.status.idle":"2023-04-27T08:30:06.54673Z","shell.execute_reply.started":"2023-04-27T08:30:06.523309Z","shell.execute_reply":"2023-04-27T08:30:06.54442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def descriptive_stats(df):\n    desc = df.describe().T\n    desc_df = pd.DataFrame(index = df. columns,\n                          columns = desc.columns,\n                          data = desc)\n    f, ax = plt.subplots(figsize = (18, 8))\n    sns.heatmap(desc,\n               annot = True,\n               cmap = cmap1,\n               fmt = \".2f\",\n               ax = ax,\n               linecolor = \"black\",\n               linewidths = 1.5,\n               cbar = False,\n               annot_kws = {\"size\" : 15})\n    plt.xticks(size = 15)\n    plt.yticks(size = 15, rotation = 0)\n    plt.title(\"Descriptive Statistics\", size = 15)\n    plt.show()\n    \n   \ndescriptive_stats(df[num_cols])","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:06.548625Z","iopub.execute_input":"2023-04-27T08:30:06.54921Z","iopub.status.idle":"2023-04-27T08:30:07.201985Z","shell.execute_reply.started":"2023-04-27T08:30:06.549146Z","shell.execute_reply":"2023-04-27T08:30:07.200926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius:10px;\n            border : black solid;\n            background-color: #5b9aa0;\n            font-size:100%;\n            text-align: left\">\n    \n<h2 style='; border:0; border-radius: 15px; font-weight: bold; font-size:220%; color:white'><center> Summary of the Dataset </center></h2> \n    \n * <b> The dataset consists of 768 rows and 8 columns </b>\n * <b> The target variable is Outcome, which contains categorical binary values 0 and 1 </b>\n * <b> The variables other than Outcome are numerical </b> \n * <b> There are technically no missing values because of lack NaN values, however when we examine closely, some 0's in the dataset indicate they are actually missing values </b>\n * <b> Descriptive statistics show that some features may have outliers (for example, 17 pregnancies can be an outlier) </b>","metadata":{}},{"cell_type":"markdown","source":"Here, we first checked the structure of the dataset to find out its dimensions, categorical and numerical values and if there are missing values or not. Then we split data into two groups: categorical and numerical values. In the next step, we calculated descriptive statistics to grasp the story of data better. As a result, we made deductions from them and summarized our findings.\n\nAs you can realize, we used functions for these operations instead of one-time codes. This approach is called <b> functional data analysis </b>, which aims to automate analysis processes and decrease coding time. \n\n<b> Further Reading: </b> <br>\nFunctional Data Analysis: https://medium.com/@sedefftaskin92/advanced-functional-exploratory-data-analysis-eda-25f2354d006a <br>\nDRY (Don't Repeat Yourself) Principle: https://medium.com/@learnstuff.io/dry-do-not-repeat-yourself-8518055b4cf","metadata":{}},{"cell_type":"markdown","source":"<a id = \"3\"></a>\n# <p style=\"background-color:#6b5b95; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ö° Exploratory Data Analysis (EDA) ‚ö°</p>","metadata":{}},{"cell_type":"markdown","source":"Exploratory Data Analysis (EDA) is an approach to get significant information and discover patterns hidden in the dataset by using visualization methods. It includes univariate, bivariate and multivariate analysis for numerical and categorical features. \n\n<b> For Further Reading: </b> <br>\nhttps://medium.com/@ugursavci/complete-exploratory-data-analysis-using-python-9f685d67d1e4","metadata":{}},{"cell_type":"code","source":"def tar_var_summary(df, tar_var):\n    colors = ['#a2b9bc', '#6b5b95', '#b2ad7f', '#feb236', '#b5e7a0', '#878f99',\n              '#d64161', '#86af49', '#ff7b25']\n    \n    fig = make_subplots(rows=1, cols=2,\n                        subplot_titles=('Countplot', 'Percentages'),\n                        specs=[[{\"type\": \"xy\"}, {'type': 'domain'}]])\n    \n    x = [str(i) for i in df[tar_var].value_counts().index]\n    y = df[tar_var].value_counts().values.tolist()\n    \n    fig.add_trace(go.Bar(x = x, y = y, text = y, \n                         textposition = \"auto\",\n                       showlegend = False,\n                        marker=dict(color=colors,\n                              line = dict(color = 'black',\n                                          width = 2))), row=1, col=1)\n    \n    fig.add_trace(go.Pie(labels = df[tar_var].value_counts().keys(),\n                         values = df[tar_var].value_counts().values,\n                         pull = [0, 0.25],\n                         hoverinfo ='label',\n                  textinfo ='percent',\n                  textfont_size = 20,\n                  textposition ='auto',\n                  marker=dict(colors=colors,\n                              line = dict(color = 'black',\n                                          width = 2))), row=1, col=2)\n\n    \n    fig.update_layout(title={'text': \"Distribution of the Target Variable\",\n                         'y':0.9,\n                         'x':0.5,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},\n                  template='plotly_dark')\n    \n    iplot(fig)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:07.20329Z","iopub.execute_input":"2023-04-27T08:30:07.204176Z","iopub.status.idle":"2023-04-27T08:30:07.216913Z","shell.execute_reply.started":"2023-04-27T08:30:07.204109Z","shell.execute_reply":"2023-04-27T08:30:07.215365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tar_var_summary(df, \"Outcome\")","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:07.218685Z","iopub.execute_input":"2023-04-27T08:30:07.219033Z","iopub.status.idle":"2023-04-27T08:30:08.779114Z","shell.execute_reply.started":"2023-04-27T08:30:07.219Z","shell.execute_reply":"2023-04-27T08:30:08.777757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def num_var_summary(df, num_var):\n    fig = make_subplots(rows = 1, cols = 2,\n                       subplot_titles = (\"Quantiles\", \"Distribution\"))\n    \n    fig.add_trace(go.Box(y = df[num_var],\n                         name = str(num_var),\n                         showlegend = False,\n                         marker_color = \"#A6D0DD\"), \n                         row = 1, col = 1)\n    \n    fig.add_trace(go.Histogram(x = df[num_var],\n                               xbins = dict(start = df[num_var].min(),\n                                            end = df[num_var].max()),\n                               showlegend = False,\n                               name = str(num_var),\n                               marker=dict(color=\"#0A4D68\",\n                                           line = dict(color = '#DBE6EC',\n                                                       width = 1))\n                              ),\n                  row = 1, col = 2)\n    \n    fig.update_layout(title={'text': num_var.capitalize(),\n                         'y':0.9,\n                         'x':0.5,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},\n                  template='plotly_dark')\n    \n    iplot(fig)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:08.780891Z","iopub.execute_input":"2023-04-27T08:30:08.782022Z","iopub.status.idle":"2023-04-27T08:30:08.792993Z","shell.execute_reply.started":"2023-04-27T08:30:08.781959Z","shell.execute_reply":"2023-04-27T08:30:08.791368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in num_cols:\n    num_var_summary(df, i)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:08.801258Z","iopub.execute_input":"2023-04-27T08:30:08.80199Z","iopub.status.idle":"2023-04-27T08:30:09.546373Z","shell.execute_reply.started":"2023-04-27T08:30:08.801946Z","shell.execute_reply":"2023-04-27T08:30:09.544903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def num_features(df, num_var, tar_var):\n    x0 = df[df[tar_var]==0][num_var]\n    x1 = df[df[tar_var]==1][num_var] \n    \n    trace1 = go.Histogram(x = x0,\n                               name = \"0\",\n                               opacity = 0.75,\n                               marker=dict(color=\"#0A4D68\",\n                                           line = dict(color = '#DBE6EC',\n                                                       width = 1)))\n                                           \n    trace2 = go.Histogram(x = x1,\n                               name = \"1\",\n                               opacity = 0.75,\n                               marker=dict(color=\"#A6D0DD\",\n                                           line = dict(color = '#DBE6EC',\n                                                       width = 1)))\n                                           \n    data = [trace1, trace2]\n                                           \n    layout = go.Layout(title={'text': num_var,\n                         'y':0.9,\n                         'x':0.5,\n                         'xanchor':'center',\n                         'yanchor':'top'},\n                         barmode='overlay',\n                         yaxis=dict(title='Count'),\n                         template = 'plotly_dark')\n                                           \n    fig = go.Figure(data=data, layout=layout)\n    \n    iplot(fig)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:09.547649Z","iopub.execute_input":"2023-04-27T08:30:09.54853Z","iopub.status.idle":"2023-04-27T08:30:09.559681Z","shell.execute_reply.started":"2023-04-27T08:30:09.548491Z","shell.execute_reply":"2023-04-27T08:30:09.558175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in num_cols:\n    num_features(df, i, \"Outcome\")","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:09.561465Z","iopub.execute_input":"2023-04-27T08:30:09.562013Z","iopub.status.idle":"2023-04-27T08:30:10.158051Z","shell.execute_reply.started":"2023-04-27T08:30:09.56196Z","shell.execute_reply":"2023-04-27T08:30:10.156729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def df_corr(df):\n    plt.figure(figsize = (12,10))\n    corr = df.corr()\n    matrix = np.triu(corr)\n    sns.heatmap(corr, annot = True, mask = matrix, cmap = \"gist_gray\")","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:10.159737Z","iopub.execute_input":"2023-04-27T08:30:10.160882Z","iopub.status.idle":"2023-04-27T08:30:10.167097Z","shell.execute_reply.started":"2023-04-27T08:30:10.160828Z","shell.execute_reply":"2023-04-27T08:30:10.165761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_corr(df)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:10.168944Z","iopub.execute_input":"2023-04-27T08:30:10.169345Z","iopub.status.idle":"2023-04-27T08:30:10.85896Z","shell.execute_reply.started":"2023-04-27T08:30:10.169305Z","shell.execute_reply":"2023-04-27T08:30:10.857958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors = ['#654E92','#6C9BCF','#A5C0DD','#EBD8B2']\nfig = go.Figure(data=go.Splom(dimensions=[dict(label=col,\n                                               values=df[col]) for col in \n                                          df[num_cols].select_dtypes(include = ['int', 'float']).columns\n                                         ],\n                showupperhalf = True, \n                text = df['Outcome'],\n                marker = dict(color = [colors[i] for i in df['Outcome']. \\\n                                     astype('category').cat.codes],\n                            showscale = False,\n                            opacity = 0.65)\n                             )\n               )\n\nfig.update_layout(title = {'text': 'Pairwise Relationships by Outcome',\n                          'xanchor': 'center',\n                          'yanchor': 'top',\n                          'x': 0.5,\n                          'y': 0.95},\n                  width = 950,\n                  height = 950,\n                  template = 'plotly_dark')\n\niplot(fig)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:10.860149Z","iopub.execute_input":"2023-04-27T08:30:10.86121Z","iopub.status.idle":"2023-04-27T08:30:11.007115Z","shell.execute_reply.started":"2023-04-27T08:30:10.86117Z","shell.execute_reply":"2023-04-27T08:30:11.00581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def detect_outliers(df, num_var):\n    \n    trace0 = go.Box(\n        y = df[num_var],\n        name = \"All Points\",\n        jitter = 0.3,\n        pointpos = -1.8,\n        boxpoints = 'all',\n        marker = dict(\n            color = '#a2b9bc'),\n        line = dict(\n            color = '#6b5b95')\n    )\n\n    trace1 = go.Box(\n        y = df[num_var],\n        name = \"Only Whiskers\",\n        boxpoints = False,\n        marker = dict(\n            color = '#b2ad7f'),\n        line = dict(\n            color = '#feb236')\n    )\n\n    trace2 = go.Box(\n        y = df[num_var],\n        name = \"Suspected Outliers\",\n        boxpoints = 'suspectedoutliers',\n        marker = dict(\n            color = '#b5e7a0',\n            outliercolor = '#878f99',\n            line = dict(\n                outliercolor = '#d64161',\n                outlierwidth = 2)),\n        line = dict(\n            color = '#86af49')\n    )\n\n    trace3 = go.Box(\n        y = df[num_var],\n        name = \"Whiskers and Outliers\",\n        boxpoints = 'outliers',\n        marker = dict(\n            color = '#6b5b95'),\n        line = dict(\n            color = '#ff7b25')\n    )\n\n    data = [trace0,trace1,trace2,trace3]\n\n    layout = go.Layout(\n        title = \"{} Outliers\".format(num_var)\n    )\n    \n    layout = go.Layout(title={'text': num_var,\n                         'y':0.9,\n                         'x':0.5,\n                         'xanchor':'center',\n                         'yanchor':'top'},\n                         barmode='overlay',\n                         yaxis=dict(title='Count'),\n                         template = 'plotly_dark')\n\n    fig = go.Figure(data=data,layout=layout)\n    \n    iplot(fig)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:11.008833Z","iopub.execute_input":"2023-04-27T08:30:11.009244Z","iopub.status.idle":"2023-04-27T08:30:11.022455Z","shell.execute_reply.started":"2023-04-27T08:30:11.009202Z","shell.execute_reply":"2023-04-27T08:30:11.021273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in num_cols:\n    detect_outliers(df, i)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:11.024044Z","iopub.execute_input":"2023-04-27T08:30:11.024443Z","iopub.status.idle":"2023-04-27T08:30:11.81959Z","shell.execute_reply.started":"2023-04-27T08:30:11.024404Z","shell.execute_reply":"2023-04-27T08:30:11.818054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius:10px;\n            border : black solid;\n            background-color: #5b9aa0;\n            font-size:100%;\n            text-align: left\">\n    \n<h2 style='; border:0; border-radius: 15px; font-weight: bold; font-size:220%; color:white'><center> Observations from Exploratory Data Analysis </center></h2> \n    \n * <b> There are no highly correlated independent variables. </b>\n * <b> The presence of outliers that can affect the models draw attention. </b>\n * <b> Despite the fact that some values like Glucose, BMI etc. that can't have the value 0, we see that these features contain 0's. So, we should handle them in the feature engineering step. </b>","metadata":{}},{"cell_type":"markdown","source":"<a id = \"4\"></a>\n# <p style=\"background-color:#6b5b95; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚õè Data Preprocessing ‚õè</p>","metadata":{}},{"cell_type":"markdown","source":"This step will include filling missing values, outlier detection and removal, feature engineering, scaling and splitting data. \n\nAs you know, missing values and outliers have always the potential to directly affect the model. Since this may lead to undesired consequences, we should handle them in a correct way. \n\nEven though there are many methods all of which are useful to some degree case by case, a common approach to handle missing values is filling them with unbiased statistics like mode, mean or median. Because removal of them means loss of information and imputation methods bring the possibility of changing the distribution of features. \n\nAs for outliers, the initial action is to detect them. Then we need to examine them carefully and determine if they affect the model or not. Analysts generally tend to keep them in the dataset, because removing them can lead to loss of information, which is an awful thing for the accuracy of models. However, if they contain extreme values, then removal of the outliers can be taken into account.\n\nAfter these processes comes the feature engineering. This step is the key of a successful model. \n\nAs you can guess, raw data lack enough information or are bloated with irrelevant variables on most occasions. We should feel the urge to fix these issues whenever we see them in our projects and the way to do so is feature engineering. Selecting the relevant features or creating the new ones always increase the accuracy of models.\n\nAnd after everythings is done, don't forget to scale your data and split it into two groups as test and train data.\n\n<b> For Further Reading </b> <br>\nhttps://www.analyticsvidhya.com/blog/2021/10/handling-missing-value/\nhttps://towardsdatascience.com/5-outlier-detection-methods-that-every-data-enthusiast-must-know-f917bf439210\nhttps://www.analyticsvidhya.com/blog/2021/03/step-by-step-process-of-feature-engineering-for-machine-learning-algorithms-in-data-science/\n","metadata":{}},{"cell_type":"code","source":"missing_values = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\ndf[missing_values] = np.where(df[missing_values] == 0, np.nan, df[missing_values])","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:11.821255Z","iopub.execute_input":"2023-04-27T08:30:11.822783Z","iopub.status.idle":"2023-04-27T08:30:11.835409Z","shell.execute_reply.started":"2023-04-27T08:30:11.822725Z","shell.execute_reply":"2023-04-27T08:30:11.833712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.matrix(df)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:11.837762Z","iopub.execute_input":"2023-04-27T08:30:11.838403Z","iopub.status.idle":"2023-04-27T08:30:12.659247Z","shell.execute_reply.started":"2023-04-27T08:30:11.838329Z","shell.execute_reply":"2023-04-27T08:30:12.657947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def missing_percentage(df):\n    total = df.isnull().sum().sort_values(ascending = False)[df.isnull().sum().sort_values(ascending = False) != 0]\n    percent = round(df.isnull().sum().sort_values(ascending = False)/len(df)*100,2)[round(df.isnull().sum().sort_values(ascending = False)/len(df)*100,2) != 0]\n    return pd.concat([total, percent], axis=1, keys=['Total','Percent'])","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:12.660829Z","iopub.execute_input":"2023-04-27T08:30:12.661199Z","iopub.status.idle":"2023-04-27T08:30:12.670016Z","shell.execute_reply.started":"2023-04-27T08:30:12.661164Z","shell.execute_reply":"2023-04-27T08:30:12.668448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_percentage(df)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:12.671956Z","iopub.execute_input":"2023-04-27T08:30:12.672476Z","iopub.status.idle":"2023-04-27T08:30:12.70096Z","shell.execute_reply.started":"2023-04-27T08:30:12.672438Z","shell.execute_reply":"2023-04-27T08:30:12.699933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.loc[df.Age.between(18,31), \"AgeGroup\"] = \"Young\"\ndf.loc[df.Age.between(31,46), \"AgeGroup\"] = \"MiddleAge\"\ndf.loc[df.Age.between(46,66), \"AgeGroup\"] = \"LateMiddleAge\"\ndf.loc[df.Age >= 66,\"AgeGroup\"] = \"Old\"","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:12.702269Z","iopub.execute_input":"2023-04-27T08:30:12.702881Z","iopub.status.idle":"2023-04-27T08:30:12.714318Z","shell.execute_reply.started":"2023-04-27T08:30:12.702833Z","shell.execute_reply":"2023-04-27T08:30:12.712756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Insulin'] = df['Insulin'].fillna(df.groupby([\"AgeGroup\", \"Outcome\"])['Insulin'].transform('median'))\ndf['Insulin'] = df['Insulin'].fillna(df.groupby('Outcome')['Insulin'].transform('median')) \ndf['SkinThickness'] = df['SkinThickness'].fillna(df.groupby('Outcome')['SkinThickness'].transform('median'))  \ndf[\"BloodPressure\"] = df[\"BloodPressure\"].fillna(df.groupby(\"Outcome\")[\"BloodPressure\"].transform('median'))\ndf['BMI'] = df['BMI'].fillna(df.groupby([\"AgeGroup\", \"Outcome\"])['BMI'].transform('median'))\ndf[\"Glucose\"] = df[\"Glucose\"].fillna(df.groupby(\"Outcome\")[\"Glucose\"].transform('median'))","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:12.716006Z","iopub.execute_input":"2023-04-27T08:30:12.716367Z","iopub.status.idle":"2023-04-27T08:30:12.737284Z","shell.execute_reply.started":"2023-04-27T08:30:12.716334Z","shell.execute_reply":"2023-04-27T08:30:12.73629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.loc[df.BMI < 18.5, \"BMIClass\"] = \"Underweight\"\ndf.loc[df.BMI.between(18.5, 25.0), \"BMIClass\"] = \"Normal\"\ndf.loc[df.BMI.between(25.0, 30.0), \"BMIClass\"] = \"Overweight\"\ndf.loc[df.BMI.between(30.0, 35.0), \"BMIClass\"] = \"Obese\"\ndf.loc[df.BMI >= 35.0 , \"BMIClass\"] = \"ExtremelyObese\"\n\ndf.loc[df.Insulin < 120  , 'InsulinThreshold'] =\"Below\"\ndf.loc[df.Insulin >= 120 , 'InsulinThreshold'] =\"Above\"\n\ndf.loc[df.Pregnancies > 0, \"HasChild\"] = \"Yes\"\ndf.loc[df.Pregnancies == 0, \"HasChild\"] = \"No\"\n\ndf.loc[df.BMI < 30, \"IsObese\"] = \"No\"\ndf.loc[df.BMI >= 30, \"IsObese\"] = \"Yes\"","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:12.738946Z","iopub.execute_input":"2023-04-27T08:30:12.740044Z","iopub.status.idle":"2023-04-27T08:30:12.763228Z","shell.execute_reply.started":"2023-04-27T08:30:12.739992Z","shell.execute_reply":"2023-04-27T08:30:12.762167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:12.765254Z","iopub.execute_input":"2023-04-27T08:30:12.766067Z","iopub.status.idle":"2023-04-27T08:30:12.791429Z","shell.execute_reply.started":"2023-04-27T08:30:12.766015Z","shell.execute_reply":"2023-04-27T08:30:12.790063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_percentage(df)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:12.793048Z","iopub.execute_input":"2023-04-27T08:30:12.793433Z","iopub.status.idle":"2023-04-27T08:30:12.820663Z","shell.execute_reply.started":"2023-04-27T08:30:12.793395Z","shell.execute_reply":"2023-04-27T08:30:12.819015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def outlier_thresholds(dataframe, col_name, q1 = 0.25, q3 = 0.75):\n    quartile1 = dataframe[col_name].quantile(q1)\n    quartile3 = dataframe[col_name].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\n\ndef replace_with_thresholds(dataframe, variable, q1 = 0.25, q3 = 0.75):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable, q1 = q1, q3 = q3)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n    \nfor col in df[num_cols].columns:\n    replace_with_thresholds(df, col, q1 = 0.1, q3 = 0.9)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:12.822525Z","iopub.execute_input":"2023-04-27T08:30:12.822922Z","iopub.status.idle":"2023-04-27T08:30:12.858152Z","shell.execute_reply.started":"2023-04-27T08:30:12.822884Z","shell.execute_reply":"2023-04-27T08:30:12.856705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cat_var_summary(df, cat_var):\n    colors = ['#a2b9bc', '#6b5b95', '#b2ad7f', '#feb236', '#b5e7a0', '#878f99',\n              '#d64161', '#86af49', '#ff7b25']\n    \n    fig = make_subplots(rows=1, cols=2,\n                        subplot_titles=('Countplot', 'Percentages'),\n                        specs=[[{\"type\": \"xy\"}, {'type': 'domain'}]])\n    \n    x = [str(i) for i in df[cat_var].value_counts().index]\n    y = df[cat_var].value_counts().values.tolist()\n    \n    fig.add_trace(go.Bar(x = x, y = y, text = y, \n                         textposition = \"auto\",\n                       showlegend = False,\n                        marker=dict(color=colors,\n                              line = dict(color = 'black',\n                                          width = 2))), row=1, col=1)\n    \n    fig.add_trace(go.Pie(labels = df[cat_var].value_counts().keys(),\n                         values = df[cat_var].value_counts().values, \n                         hoverinfo ='label',\n                  textinfo ='percent',\n                  textfont_size = 20,\n                  textposition ='auto',\n                  marker=dict(colors=colors,\n                              line = dict(color = 'black',\n                                          width = 2))), row=1, col=2)\n\n    \n    fig.update_layout(title={'text': cat_var,\n                         'y':0.9,\n                         'x':0.5,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},\n                  template='plotly_dark')\n    \n    iplot(fig)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:12.865467Z","iopub.execute_input":"2023-04-27T08:30:12.865927Z","iopub.status.idle":"2023-04-27T08:30:12.878613Z","shell.execute_reply.started":"2023-04-27T08:30:12.865885Z","shell.execute_reply":"2023-04-27T08:30:12.87711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in [\"BMIClass\", \"AgeGroup\", \"InsulinThreshold\", \"HasChild\", \"IsObese\"]:\n    cat_var_summary(df, i)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:12.880142Z","iopub.execute_input":"2023-04-27T08:30:12.880585Z","iopub.status.idle":"2023-04-27T08:30:13.268791Z","shell.execute_reply.started":"2023-04-27T08:30:12.880547Z","shell.execute_reply":"2023-04-27T08:30:13.267461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_cols = [\"BMIClass\", \"AgeGroup\", \"InsulinThreshold\", \"HasChild\", \"IsObese\"]\ndf = pd.get_dummies(df, columns=cat_cols)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:13.270595Z","iopub.execute_input":"2023-04-27T08:30:13.271016Z","iopub.status.idle":"2023-04-27T08:30:13.283393Z","shell.execute_reply.started":"2023-04-27T08:30:13.27098Z","shell.execute_reply":"2023-04-27T08:30:13.281874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:13.28511Z","iopub.execute_input":"2023-04-27T08:30:13.285506Z","iopub.status.idle":"2023-04-27T08:30:13.314314Z","shell.execute_reply.started":"2023-04-27T08:30:13.285469Z","shell.execute_reply":"2023-04-27T08:30:13.312946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rs = RobustScaler()\ndf[num_cols] = rs.fit_transform(df[num_cols])","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:13.315794Z","iopub.execute_input":"2023-04-27T08:30:13.317029Z","iopub.status.idle":"2023-04-27T08:30:13.332942Z","shell.execute_reply.started":"2023-04-27T08:30:13.316963Z","shell.execute_reply":"2023-04-27T08:30:13.331484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = df[\"Outcome\"]\nX = df.drop([\"Outcome\"], axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:13.334707Z","iopub.execute_input":"2023-04-27T08:30:13.335759Z","iopub.status.idle":"2023-04-27T08:30:13.348252Z","shell.execute_reply.started":"2023-04-27T08:30:13.335703Z","shell.execute_reply":"2023-04-27T08:30:13.347012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius:10px;\n            border : black solid;\n            background-color: #5b9aa0;\n            font-size:100%;\n            text-align: left\">\n    \n<h2 style='; border:0; border-radius: 15px; font-weight: bold; font-size:220%; color:white'><center> Summary </center></h2> \n    \n* <b> Initially, we checked the missing values that can't be directly discerned. Then filled them with median. </b>\n* <b> Created new features to increase the accuracy. </b>\n* <b> Replaced outliers in accordance with a low threshold value. </b>\n* <b> Scaled data and split it into test and train data. </b>    \n* <b> Now, we are ready for modeling. </b>","metadata":{}},{"cell_type":"markdown","source":"<a id = \"5\"></a>\n# <p style=\"background-color:#6b5b95; font-family:newtimeroman;color:#FFF9ED; font-size:150%; text-align:center; border-radius: 15px 50px;\"> ‚ò£ Models ‚ò£</p>","metadata":{}},{"cell_type":"code","source":"def model_performance(model):\n    y_pred = model.fit(X_train, y_train).predict(X_test)\n    \n    fig = make_subplots(\n    rows=1, cols=2,\n    subplot_titles=(\"Confusion Matrix\", \"Metrics\"))\n    \n    confusion = confusion_matrix(y_test, y_pred)\n    tp = confusion[1,1]\n    fn = confusion[1,0]\n    fp = confusion[0,1]\n    tn = confusion[0,0]\n    accuracy  =  ((tp+tn)/(tp+tn+fp+fn))\n    precision =  (tp/(tp+fp))\n    recall    =  (tp/(tp+fn))\n    f1_score  =  (2*(((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp))+(tp/(tp+fn)))))\n\n    colors = ['#93e4c1', '#3baea0', '#118a7e', '#1f6f78']\n\n    show_metrics = pd.DataFrame(data=[[accuracy , precision, recall, f1_score]])\n    show_metrics = show_metrics.T\n\n    fig.add_trace(go.Heatmap(z = confusion  ,x = [\"0 (pred)\",\"1 (pred)\"],\n                         y = [\"0 (true)\",\"1 (true)\"],xgap = 2, ygap = 2, \n                         colorscale=\"darkmint\", showscale  = False), \n                         row = 1, col = 1)\n    \n    fig.add_trace(go.Bar(x = (show_metrics[0].values), \n                    y = ['Accuracy', 'Precision', 'Recall', 'F1_score'], \n                    text = np.round_(show_metrics[0].values,4),\n                    textposition = 'auto', textfont=dict(color='white'),\n                    orientation = 'h', opacity = 1, marker=dict(\n            color=colors,\n            line=dict(color='white',width=1.5))), row = 1, col = 2)\n    \n    fig.update_layout(title={'text': model.__class__.__name__,\n                         'y':0.9,\n                         'x':0.5,\n                         'xanchor': 'center',\n                         'yanchor': 'top'},\n                  template='plotly_dark')\n    \n    iplot(fig)                       ","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:13.350226Z","iopub.execute_input":"2023-04-27T08:30:13.350588Z","iopub.status.idle":"2023-04-27T08:30:13.365185Z","shell.execute_reply.started":"2023-04-27T08:30:13.350554Z","shell.execute_reply":"2023-04-27T08:30:13.363713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_state = 42\nmodels = [GaussianNB(), \n          DecisionTreeClassifier(random_state = random_state),\n          SVC(random_state = random_state, probability = True),\n          RandomForestClassifier(random_state = random_state),\n          LogisticRegression(random_state = random_state),\n          KNeighborsClassifier(),\n          GradientBoostingClassifier(random_state = random_state),\n          CatBoostClassifier(random_state = random_state),\n          XGBClassifier(random_state = random_state),\n          LGBMClassifier(random_state = random_state)]","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:13.366915Z","iopub.execute_input":"2023-04-27T08:30:13.368257Z","iopub.status.idle":"2023-04-27T08:30:13.387505Z","shell.execute_reply.started":"2023-04-27T08:30:13.368202Z","shell.execute_reply":"2023-04-27T08:30:13.386095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for model in models:\n    model_performance(model)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:30:13.389467Z","iopub.execute_input":"2023-04-27T08:30:13.390697Z","iopub.status.idle":"2023-04-27T08:30:18.66225Z","shell.execute_reply.started":"2023-04-27T08:30:13.390634Z","shell.execute_reply":"2023-04-27T08:30:18.661103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius:10px;\n            border : black solid;\n            background-color: #5b9aa0;\n            font-size:100%;\n            text-align: left\">\n    \n<h2 style='; border:0; border-radius: 15px; font-weight: bold; font-size:220%; color:white'><center> Result </center></h2> \n    \n* <b> After trying various algorithms, Random Forest gave us a roughly 88% accuracy rate. It can be increased by creating new features or adding relevant external data to the model. Beside them, we can use stacking or tuning methods, but they won't be included in this project. </b>","metadata":{}}]}